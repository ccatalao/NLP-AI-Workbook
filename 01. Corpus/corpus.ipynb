{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINGUAGEM NATURAL E INTELIGÊNCIA ARTIFICIAL\n",
    "### Aplicações e tutoriais para a língua portuguesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINGUÍSTICA DE CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos Catalão Alves  \n",
    "20 Maio, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação:\n",
    "Programa que cria um corpus a partir de um ficheiro csv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Os textos são lidos em ficheiro csv, delimitado por tabs (*imprensa.csv*)  \n",
    "- O resultado final é um ficheiro de texto com anotação de titulo, parágrafo e frase (*corpo.txt*)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biblioteca NLTK - Natural Langage Processing Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta aplicação usa ficheiros csv, delimitados por tabs. O exemplo aqui apresentado lê os dados a partir de um ficheiro de demonstração *(imprensa.csv)*, contendo artigos da plataforma *Ciência Viva na Imprensa Regional*, com os seguintes campos:\n",
    "- identificador do artigo\n",
    "- identificador do autor\n",
    "- data do artigo\n",
    "- título\n",
    "- texto do artigo\n",
    "\n",
    "O programa é aplicável sem alterações substanciais a qualquer outro ficheiro csv, desde que delimitado por tabs e contendo o mesmo número e ordem de campos. Neste caso será só necessário alterar o valor da variável **FICHEIRO**. \n",
    "Caso se verifiquem alterações no número e ordem dos campos, será necessário adaptar também a variável *pos_ficheiro* à nova posição dos campos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FICHEIRO = \"imprensa.csv\"\n",
    "CORPO = \"corpo.txt\"\n",
    "GENERO = \"noticia\"\n",
    "TEXTO_INICIO = \"<texto id=\"\n",
    "TEXTO_FIM = \"\\n</texto>\\n\"\n",
    "TITULO_INICIO = \"<t> \"\n",
    "TITULO_FIM = \" </t>\"\n",
    "PARAGRAFO_INICIO = \"\\n<p>\"\n",
    "PARAGRAFO_FIM = \"\\n\\n</p>\"\n",
    "FRASE_INICIO = \"\\n<s> \"\n",
    "FRASE_FIM = \" </s>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textos para processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# recebe os dados do ficheiro fonte\n",
    "dados = pd.read_csv(FICHEIRO, delimiter = \"\\t\", quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criação do ficheiro de texto para o corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# abre um ficheiro de texto para registar o corpus\n",
    "corpus = open(CORPO, \"w\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação do separador frásico NLTK (versão para português)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usa o separador frásico do NLTK para português\n",
    "separador_frasico = nltk.data.load(\"tokenizers/punkt/portuguese.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processa textos e cria o corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# para cada linha do ficheiro fonte\n",
    "for indice in range(len(dados)):\n",
    "\n",
    "    tx = \"\" # texto\n",
    "    p = [] # lista de parágrafos\n",
    "    pos_ficheiro = 2 # coluna do ficheiro fonte com a data \n",
    "    \n",
    "    # regista cabeçalho do texto com metadados\n",
    "    data = str(dados.iloc[indice, pos_ficheiro])\n",
    "    data = data[6:8]+\"-\"+data[4:6]+\"-\" + data[:4]\n",
    "    corpus.write(TEXTO_INICIO + str(indice) + \" \" + \"gen=\" + GENERO + \" \" \n",
    "                 + \"data=\" + data + \" \" + \"origem=Ciência Viva na Imprensa Regional\" + \">\")\n",
    "    \n",
    "    # regista o título\n",
    "    pos_ficheiro = 3 # coluna do ficheiro fonte com a data\n",
    "    corpus.write(PARAGRAFO_INICIO)\n",
    "    corpus.write(FRASE_INICIO + TITULO_INICIO + dados.iloc[indice, pos_ficheiro] \n",
    "                 + TITULO_FIM + FRASE_FIM)\n",
    "    corpus.write(PARAGRAFO_FIM)     \n",
    "           \n",
    "    # recebe texto do ficheiro fonte\n",
    "    pos_ficheiro = 4 # coluna do ficheiro fonte com o texto \n",
    "    tx = dados.iloc[indice, 4]  \n",
    "    \n",
    "    # separa os parágrafos\n",
    "    p = tx.split('\\n\\n') \n",
    "        \n",
    "    # processa cada parágrafo\n",
    "    for x in range (0, len(p)):\n",
    "        \n",
    "        if p[x] != \" \": # se o parágrafo não é uma linha em branco\n",
    "                        \n",
    "            corpus.write(PARAGRAFO_INICIO)            \n",
    "            \n",
    "            frases = separador_frasico.tokenize(p[x])\n",
    "            \n",
    "            for frase in frases:\n",
    "                corpus.write(FRASE_INICIO + frase + FRASE_FIM)\n",
    "            \n",
    "            corpus.write(PARAGRAFO_FIM)\n",
    "\n",
    "    corpus.write(TEXTO_FIM)\n",
    "\n",
    "corpus.close() # fecha o ficheiro com o corpus\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
