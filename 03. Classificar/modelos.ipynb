{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINGUAGEM NATURAL E INTELIGÊNCIA ARTIFICIAL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODELOS DE CLASSIFICAÇÃO AUTOMÁTICA DE TEXTO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos Catalão Alves  \n",
    "13 Maio, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obter e comparar os resultados de diferentes modelos, usados em Aprendizagem Máquina, para classificação automática de textos. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos utilizados são:  \n",
    "\n",
    "1. k-Nearest Neighbor (kNN)   \n",
    "2. SGDClassifier  \n",
    "3. Perceptron  \n",
    "4. Naive Bayes (modelos Multinominal e Bernoulli)  \n",
    "\n",
    "Em cada um dos modelos será possível observar um relatório detalhado, incluindo diversos dados métricos. É produzido também um gráfico comparativo dos diferentes modelos. \n",
    "\n",
    "Os dados são lidos num ficheiro csv, delimitado por tabs (textos_treino.csv), e são divididos em séries para treino e para teste. Os resultados são obtidos a partir de uma comparação entre as classificações previstas pelos modelos treinados e as classificações reais à partida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Livrarias python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Livrarias NLTK - Natural Langage Processing Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Livrarias SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "report = []\n",
    "categorias = [ \"Astronomia\",\"Biologia\",\"Geologia\",\"Engenharia\",\"Patrimonio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenizar(texto, stemizar=True, lingua=\"portuguese\"):\n",
    "\n",
    "    # Usa o SnowballStemmer do NLTK para português\n",
    "    stemizador = SnowballStemmer(lingua)\n",
    "\n",
    "    # Tokeniza por frase e por palavra\n",
    "    tokens = [word.lower() for frase in nltk.sent_tokenize(texto) for word in nltk.word_tokenize(frase)]\n",
    "    \n",
    "    # Aplica NLTK stopwords \n",
    "    stop_words_pt = set(stopwords.words(lingua)) \n",
    "    \n",
    "    # Filtra as palavras que não têm letras, e as que estão na lista de stopwords\n",
    "    tokens_filtrados = []\n",
    "    for token in tokens:\n",
    "        if re.search(\"[a-zA-Z]\", token):\n",
    "            if token not in stopwords.words(lingua):\n",
    "                if token not in stop_words_pt:\n",
    "                    tokens_filtrados.append(token)\n",
    "                if stemizar:\n",
    "                    stems = [stemizador.stem(token) for token in tokens_filtrados]\n",
    "    return stems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Relatório de classificação\n",
    "def reporta(clf, modelo):\n",
    "    \n",
    "    print(\"\\nModelo: %s\" % modelo)\n",
    "    print('_' * 80)\n",
    "\n",
    "    clf.fit(X_treino, y_treino)\n",
    "    previsao = clf.predict(X_teste)\n",
    "    score = metrics.accuracy_score(y_teste, previsao)\n",
    "    print(\"\\nacurancy: %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"\\nTermos mais relevantes em cada categoria:\\n\")\n",
    "        for i, label in enumerate(categorias):\n",
    "            top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "            print(trim(\"%s: \\t %s\" % (label, \"  \".join(termos[top10]))))\n",
    "        print()\n",
    "\n",
    "\n",
    "    print(\"\\nRelatório:\")\n",
    "    print(metrics.classification_report(y_teste, previsao, target_names=categorias))\n",
    "    print(\"\\nconfusion matrix:\")\n",
    "    print(metrics.confusion_matrix(y_teste, previsao))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    # Assegura apresentação dentro dos limites das 80 colunas do terminal\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importa ficheiro csv com textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando os dados de treino\n",
    "dados = pd.read_csv('textos_treino.csv', delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partição dos dados em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 documentos de treino\n",
      "4 documentos de teste\n",
      "5 categorias\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = dados[\"texto\"]\n",
    "y = dados[\"target\"]\n",
    "\n",
    "# Dividir documentos em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"%d documentos de treino\" % (len(X_treino)))\n",
    "print(\"%d documentos de teste\" % (len(X_teste)))\n",
    "print(\"%d categorias\" % len(categorias))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados de treino: Pré-processamento e vectorização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A extrair termos de 16 documentos de treino ...\n",
      "Termos extraídos em: 5.7s\n",
      "documentos: 16, termos: 780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A extrair termos de %d documentos de treino ...\"  % (len(X_treino)))\n",
    "t0 = time()\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english', tokenizer=tokenizar)\n",
    "X_treino = vectorizer.fit_transform(X_treino)\n",
    "duracao = time() - t0\n",
    "print(\"Termos extraídos em: {0:.1f}s\".format(duracao))\n",
    "print(\"documentos: %d, termos: %d\" % X_treino.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados de teste: Pré-processamento e vectorização "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A extrair termos de 4 documentos de teste ...\n",
      "Termos extraídos em: 1.5s\n",
      "documentos: 4, termos: 780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"A extrair termos de %d documentos de teste ...\"  % (len(X_teste)))\n",
    "t0 = time()\n",
    "X_teste = vectorizer.transform(X_teste)\n",
    "duracao = time() - t0\n",
    "print(\"Termos extraídos em: {0:.1f}s\".format(duracao))\n",
    "print(\"documentos: %d, termos: %d\" % X_teste.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associar vectores aos termos originais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ligar cada vector ao termo original, para mostrar os mais relevantes\n",
    "termos = vectorizer.get_feature_names()\n",
    "if termos:\n",
    "    termos = np.asarray(termos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicar os modelos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: Perceptron\n",
      "________________________________________________________________________________\n",
      "\n",
      "acurancy: 1.000\n",
      "\n",
      "Termos mais relevantes em cada categoria:\n",
      "\n",
      "Astronomia: \t pol  conceit  observacional  moviment  aparent  estrel  constel...\n",
      "Biologia: \t medicin  muit  alcobac  valor  equilíbri  constitu  candeeir  esp...\n",
      "Geologia: \t geolog  human  roch  gerês  granít  geoform  vertent  instabil  r...\n",
      "Engenharia: \t carvã  electr  termoeléctr  sin  queim  betumin  plataform  sul...\n",
      "Patrimonio: \t project  igrej  estud  ermid  investig  alentej  pintur  diagnó...\n",
      "\n",
      "\n",
      "Relatório:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Astronomia       1.00      1.00      1.00         1\n",
      "   Biologia       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[1 0]\n",
      " [0 3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 2, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "report.append(reporta(Perceptron(max_iter=50), \"Perceptron\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbor (kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: KNeighbors Classifier\n",
      "________________________________________________________________________________\n",
      "\n",
      "acurancy: 0.250\n",
      "\n",
      "Relatório:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Astronomia       0.50      1.00      0.67         1\n",
      "   Biologia       0.00      0.00      0.00         3\n",
      "   Geologia       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.12      0.25      0.17         4\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[1 0 0]\n",
      " [1 0 2]\n",
      " [0 0 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 3, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "report.append(reporta(KNeighborsClassifier(n_neighbors=10), \"KNeighbors Classifier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: SGDC Classifier\n",
      "________________________________________________________________________________\n",
      "\n",
      "acurancy: 0.250\n",
      "\n",
      "Termos mais relevantes em cada categoria:\n",
      "\n",
      "Astronomia: \t introdu  explic  noit  sessã  particip  astronom  relógi  estre...\n",
      "Biologia: \t sop  muit  equilíbri  valor  alcobac  constitu  candeeir  espéc  ...\n",
      "Geologia: \t característ  gerês  geoform  granít  vertent  instabil  rio  regi...\n",
      "Engenharia: \t hidroeléctr  entrou  industrial  energ  construçã  mw  gui  ser...\n",
      "Patrimonio: \t diagnóst  investig  pintur  estud  ermid  conserv  igrej  alent...\n",
      "\n",
      "\n",
      "Relatório:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Astronomia       1.00      1.00      1.00         1\n",
      "   Biologia       0.00      0.00      0.00         3\n",
      "   Geologia       0.00      0.00      0.00         0\n",
      " Engenharia       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.25      0.25      0.25         4\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[1 0 0 0]\n",
      " [0 0 2 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 4, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "report.append(reporta(SGDClassifier(alpha=.0001, max_iter=50, penalty=\"elasticnet\"), \"SGDC Classifier\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: MultinomialNB\n",
      "________________________________________________________________________________\n",
      "\n",
      "acurancy: 1.000\n",
      "\n",
      "Termos mais relevantes em cada categoria:\n",
      "\n",
      "Astronomia: \t astronóm  particip  activ  planetári  relógi  sessõ  estrel  co...\n",
      "Biologia: \t serr  valor  alcobac  equilíbri  constitu  candeeir  espéc  val  ...\n",
      "Geologia: \t vertent  sobr  divers  activ  instabil  rio  regiã  val  peg  din...\n",
      "Engenharia: \t entrou  industrial  energ  construçã  gui  mw  visit  servic  p...\n",
      "Patrimonio: \t pintur  project  conserv  alentej  estud  igrej  investig  lev ...\n",
      "\n",
      "\n",
      "Relatório:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Astronomia       1.00      1.00      1.00         1\n",
      "   Biologia       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00         4\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[1 0]\n",
      " [0 3]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 2, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n"
     ]
    }
   ],
   "source": [
    "report.append(reporta(MultinomialNB(alpha=.01), \"MultinomialNB\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: BernoulliNB\n",
      "________________________________________________________________________________\n",
      "\n",
      "acurancy: 0.250\n",
      "\n",
      "Termos mais relevantes em cada categoria:\n",
      "\n",
      "Astronomia: \t long  activ  tem  explic  sessõ  constel  sobr  planetári  sol ...\n",
      "Biologia: \t estend  mamífer  cel  cavidad  madeireir  caud  ribeir  carrascal...\n",
      "Geologia: \t vam  ciênc  desd  paisag  roch  sobr  rio  activ  regiã  geológ\n",
      "Engenharia: \t industrial  construçã  servic  energ  entrou  potênc  mw  grup ...\n",
      "Patrimonio: \t descobert  preserv  pretende-s  cruz  project  prol  construír ...\n",
      "\n",
      "\n",
      "Relatório:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " Astronomia       1.00      1.00      1.00         1\n",
      "   Biologia       0.00      0.00      0.00         3\n",
      "   Geologia       0.00      0.00      0.00         0\n",
      " Engenharia       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.25      0.25      0.25         4\n",
      "\n",
      "\n",
      "confusion matrix:\n",
      "[[1 0 0 0]\n",
      " [0 0 2 1]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 4, does not match size of target_names, 5\n",
      "  .format(len(labels), len(target_names))\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/calves/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report.append(reporta(BernoulliNB(alpha=.01), \"BernoulliNB\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRÁFICO COMPARATIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAEyCAYAAADuuzlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115b8ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indices = np.arange(len(report))\n",
    "report = [[x[i] for x in report] for i in range(2)]\n",
    "clf_names, score = report\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
