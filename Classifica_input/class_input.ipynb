{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINGUAGEM NATURAL E INTELIGÊNCIA ARTIFICIAL\n",
    "### Aplicações e tutoriais para a língua portuguesa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICAÇÃO AUTOMÁTICA DE FRASE ENTRADA PELO UTILIZADOR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlos Catalão Alves  \n",
    "20 Outubro, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programa que classifica uma frase introduzida pelo utilizador, com aplicação de aprendizagem automática supervisionada.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "O modelo é treinado com um ficheiro csv (treinar.csv), a partir de uma tabela \n",
    "criada para o efeito com dados da Ciência Viva no Verão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "O resultado final é a indicação da categoria/área de actividade, com a respectiva probabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bobliotecas python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas NLTK - Natural Langage Processing Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas SciKit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "novo_corpus = []\n",
    "input_corpus = []\n",
    "categorias = [ \"outra\",\"Astronomia\",\"Biologia\",\"Geologia\",\"Engenharia\",\"Patrimonio\"]\n",
    "TREINO = \"treinar.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def atomizar(texto, radical=True, lingua=\"portuguese\"):\n",
    "\n",
    "    # usa o SnowballStemmer do NLTK para português para obter o radical\n",
    "    radicalizador = SnowballStemmer(lingua)\n",
    "\n",
    "    # atomiza por frase e palavra\n",
    "    atomos = [word.lower() for frase in nltk.sent_tokenize(texto) for word in nltk.word_tokenize(frase)]\n",
    "    \n",
    "    # Aplica NLTK stopwords \n",
    "    stop_words_pt = set(stopwords.words(lingua)) \n",
    "    \n",
    "    # Filtra as palavras que não têm letras, e as que estão na lista de stopwords\n",
    "    atomos_filtrados = []\n",
    "    for atomo in atomos:\n",
    "        if re.search(\"[a-zA-Z]\", atomo):\n",
    "            if atomo not in stopwords.words(lingua):\n",
    "                if atomo not in stop_words_pt:\n",
    "                    atomos_filtrados.append(atomo)\n",
    "                if radical:\n",
    "                    radicais = [radicalizador.stem(atomo) for atomo in atomos_filtrados]\n",
    "    return radicais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textos para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando os dados de treino\n",
    "dados_treino = pd.read_csv(TREINO, delimiter = \"\\t\", quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-processamento dos textos de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A treinar com textos classificados ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nA treinar com textos classificados ...\\n\")\n",
    "for i in range(len(dados_treino)):    \n",
    "    atomos = atomizar(dados_treino[\"texto\"][i], radical=True, lingua=\"portuguese\")    \n",
    "    # refaz cada linha com os tokens processados\n",
    "    atomos = ' '.join(atomos)\n",
    "    corpus.append(atomos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcular a matriz TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vectorizar só as 100 palavras mais frequentes\n",
    "cv = CountVectorizer(max_features = 100)\n",
    "\n",
    "# Obter a variável independente X (ie., os textos já classificados)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X)\n",
    "\n",
    "# Obter a variável independente y (a classificação dos textos)\n",
    "# \":\" todas as linhas, e \"2\" a coluna com a classificação\n",
    "y = dados_treino.iloc[:, 2].values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicar o modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aplicar o modelo Multinominal Naive Bayes\n",
    "clf = MultinomialNB().fit(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificar frase introduzida pelo utilizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    try: \n",
    "        # Calcular a matiz TF-IDF do novo texto\n",
    "        my_input = input(\"\\nEscreva uma frase para classificar -> \")\n",
    "        input_corpus = []\n",
    "        novo_corpus = []\n",
    "        \n",
    "        input_corpus.append(my_input)\n",
    "        \n",
    "        print(\"\\nA processar a frase ...\\n\")\n",
    "        atomos = atomizar(input_corpus[0], radical=True, lingua=\"portuguese\")    \n",
    "        # refaz linha com os termos processados\n",
    "        atomos = ' '.join(atomos)\n",
    "        novo_corpus.append(atomos)\n",
    "        \n",
    "        \n",
    "        X_novo = cv.transform(novo_corpus)\n",
    "        X_novo_tfidf = tfidf_transformer.transform(X_novo)\n",
    "        \n",
    "        # Previsão de classificações e respectivas probabilidades\n",
    "        \n",
    "        previsoes = clf.predict(X_novo_tfidf)\n",
    "        probabilidades = clf.predict_proba(X_novo_tfidf)\n",
    "        \n",
    "        previsao = previsoes[0]\n",
    "        categoria = categorias[previsao]\n",
    "        probabilidade = (probabilidades[0][previsao-1]) * 100\n",
    "        \n",
    "        if probabilidade > 50: \n",
    "        \n",
    "            print(novo_corpus[0] + '\\n')\n",
    "            print(\"\\nCategoria: %s. Probabilidade = %f\" % (categoria, probabilidade))\n",
    "        else:\n",
    "            print(\"\\nNão consigo classificar essa frase com um grau de confiança superior a 50%. Tente de novo ...\\n\")\n",
    "            \n",
    "    except(KeyboardInterrupt, EOFError, SystemExit):\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
